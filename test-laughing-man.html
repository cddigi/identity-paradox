<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Laughing Man Face Detection Test</title>
    <style>
        body {
            font-family: 'Courier New', monospace;
            background-color: #0a0a0a;
            color: #00CED1;
            margin: 20px;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .test-section {
            margin: 20px 0;
            padding: 20px;
            border: 1px solid #00CED1;
            border-radius: 8px;
        }
        button {
            background-color: #00CED1;
            color: #0a0a0a;
            border: none;
            padding: 10px 20px;
            margin: 5px;
            cursor: pointer;
            border-radius: 4px;
            font-weight: bold;
        }
        button:hover {
            background-color: #00FFFF;
        }
        .video-container {
            display: flex;
            gap: 20px;
            margin: 20px 0;
        }
        .video-box {
            flex: 1;
        }
        video, canvas {
            width: 100%;
            max-width: 500px;
            border: 2px solid #00CED1;
            background-color: #000;
        }
        .result {
            margin: 10px 0;
            padding: 15px;
            background-color: rgba(0, 206, 209, 0.1);
            border-radius: 4px;
            font-family: monospace;
        }
        .success {
            border-left: 4px solid #00FF00;
        }
        .error {
            border-left: 4px solid #FF0000;
        }
        .info {
            border-left: 4px solid #00CED1;
        }
        #statusLog {
            height: 200px;
            overflow-y: auto;
            background-color: rgba(0, 0, 0, 0.5);
            padding: 10px;
            border: 1px solid #00CED1;
            margin-top: 20px;
            font-size: 12px;
        }
        .log-entry {
            margin: 2px 0;
        }
        .stats {
            display: flex;
            gap: 20px;
            margin: 20px 0;
        }
        .stat-box {
            padding: 10px;
            background-color: rgba(0, 206, 209, 0.2);
            border-radius: 4px;
            text-align: center;
        }
        .stat-value {
            font-size: 24px;
            font-weight: bold;
            color: #00FFFF;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé≠ Laughing Man Face Detection Test</h1>
        
        <div class="test-section">
            <h2>Test Controls</h2>
            <div>
                <button onclick="startProcessing()" id="startBtn" disabled>Start Face Detection</button>
                <button onclick="stopProcessing()" id="stopBtn" disabled>Stop</button>
                <button onclick="startRecording()" id="recordBtn" disabled>Start Recording</button>
                <button onclick="stopRecording()" id="stopRecordBtn" disabled>Stop Recording</button>
                <button onclick="clearLog()">Clear Log</button>
            </div>
            <div id="initStatus" style="margin: 10px 0; color: #FFD700;">üîÑ Initializing webcam and models...</div>
            
            <div>
                <label>
                    <input type="checkbox" id="showDebugInfo" checked> Show Debug Info
                </label>
                <label style="margin-left: 20px;">
                    <input type="checkbox" id="smoothTracking" checked> Smooth Tracking
                </label>
            </div>
        </div>

        <div class="test-section">
            <h2>Video Processing</h2>
            <div class="video-container">
                <div class="video-box">
                    <h3>Original Video</h3>
                    <video id="testVideo" controls></video>
                </div>
                <div class="video-box">
                    <h3>Processed Output</h3>
                    <canvas id="outputCanvas"></canvas>
                </div>
            </div>
            
            <div class="stats">
                <div class="stat-box">
                    <div>Faces Detected</div>
                    <div class="stat-value" id="faceCount">0</div>
                </div>
                <div class="stat-box">
                    <div>FPS</div>
                    <div class="stat-value" id="fps">0</div>
                </div>
                <div class="stat-box">
                    <div>Processing Time</div>
                    <div class="stat-value" id="processTime">0ms</div>
                </div>
                <div class="stat-box">
                    <div>Frames Processed</div>
                    <div class="stat-value" id="frameCount">0</div>
                </div>
                <div class="stat-box">
                    <div>Recording Status</div>
                    <div class="stat-value" id="recordStatus">Ready</div>
                </div>
            </div>
        </div>

        <div class="test-section">
            <h2>Test Results</h2>
            <div id="testResults"></div>
        </div>

        <div class="test-section">
            <h2>Debug Log</h2>
            <div id="statusLog"></div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script>
        // Global variables
        let video, canvas, ctx;
        let isProcessing = false;
        let frameCount = 0;
        let lastFrameTime = 0;
        let faceTracker = new Map();
        let logo;
        let mediaRecorder;
        let recordedChunks = [];
        let isRecording = false;

        // Laughing Man Logo class
        class LaughingManLogo {
            constructor() {
                this.rotation = 0;
                this.text = "I thought what I'd do was, I'd pretend I was one of those deaf-mutes";
            }
            
            draw(ctx, x, y, radius) {
                const showDebug = document.getElementById('showDebugInfo').checked;
                
                ctx.save();
                ctx.translate(x, y);
                
                // Semi-transparent background circle
                ctx.beginPath();
                ctx.arc(0, 0, radius, 0, 2 * Math.PI);
                ctx.fillStyle = 'rgba(0, 206, 209, 0.85)';
                ctx.fill();
                
                // White inner circle
                ctx.beginPath();
                ctx.arc(0, 0, radius * 0.9, 0, 2 * Math.PI);
                ctx.fillStyle = 'rgba(255, 255, 255, 0.9)';
                ctx.fill();
                
                // Laughing face
                ctx.strokeStyle = '#1a1a1a';
                ctx.lineWidth = 3;
                
                // Eyes
                const eyeRadius = radius * 0.08;
                const eyeY = -radius * 0.2;
                const eyeX = radius * 0.25;
                
                ctx.beginPath();
                ctx.arc(-eyeX, eyeY, eyeRadius, 0, 2 * Math.PI);
                ctx.fillStyle = '#1a1a1a';
                ctx.fill();
                
                ctx.beginPath();
                ctx.arc(eyeX, eyeY, eyeRadius, 0, 2 * Math.PI);
                ctx.fill();
                
                // Smile
                ctx.beginPath();
                ctx.arc(0, 0, radius * 0.4, 0.2 * Math.PI, 0.8 * Math.PI);
                ctx.stroke();
                
                // Rotating text
                this.drawRotatingText(ctx, radius * 0.75);
                
                // Debug info
                if (showDebug) {
                    ctx.fillStyle = 'rgba(255, 255, 255, 0.8)';
                    ctx.font = '12px monospace';
                    ctx.textAlign = 'center';
                    ctx.fillText(`(${Math.round(x)}, ${Math.round(y)})`, 0, radius + 20);
                }
                
                ctx.restore();
                this.rotation += 0.02;
            }
            
            drawRotatingText(ctx, radius) {
                ctx.save();
                ctx.rotate(this.rotation);
                ctx.font = `${radius * 0.12}px monospace`;
                ctx.fillStyle = '#000000';
                ctx.textAlign = 'center';
                ctx.textBaseline = 'middle';
                
                const chars = this.text.split('');
                const angleStep = (2 * Math.PI) / chars.length;
                
                chars.forEach((char, i) => {
                    const angle = i * angleStep;
                    ctx.save();
                    ctx.rotate(angle);
                    ctx.translate(0, -radius);
                    ctx.rotate(-angle - this.rotation);
                    ctx.fillText(char, 0, 0);
                    ctx.restore();
                });
                
                ctx.restore();
            }
        }

        // Logging functions
        function log(message, type = 'info') {
            const logDiv = document.getElementById('statusLog');
            const timestamp = new Date().toLocaleTimeString();
            const entry = document.createElement('div');
            entry.className = 'log-entry';
            entry.style.color = type === 'error' ? '#FF0000' : 
                               type === 'success' ? '#00FF00' : '#00CED1';
            entry.textContent = `[${timestamp}] ${message}`;
            logDiv.appendChild(entry);
            logDiv.scrollTop = logDiv.scrollHeight;
        }

        function clearLog() {
            document.getElementById('statusLog').innerHTML = '';
        }

        function updateResult(message, type = 'info') {
            const resultDiv = document.getElementById('testResults');
            const result = document.createElement('div');
            result.className = `result ${type}`;
            result.textContent = message;
            resultDiv.appendChild(result);
        }

        // Initialize face detection
        async function initializeFaceDetection() {
            try {
                log('Loading face detection models...');
                updateResult('üîÑ Initializing face detection...', 'info');
                
                // Load models from CDN
                const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
                await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
                
                log('Face detection models loaded successfully', 'success');
                updateResult('‚úÖ Face detection models loaded', 'success');
                
                // Initialize logo
                logo = new LaughingManLogo();
                
                return true;
            } catch (error) {
                log(`Failed to load models: ${error.message}`, 'error');
                updateResult(`‚ùå Failed to load face detection models: ${error.message}`, 'error');
                return false;
            }
        }

        // Load test video
        async function loadTestVideo() {
            try {
                video = document.getElementById('testVideo');
                canvas = document.getElementById('outputCanvas');
                ctx = canvas.getContext('2d');
                
                // Use webcam instead of local video to avoid CORS
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                
                await new Promise((resolve, reject) => {
                    video.onloadedmetadata = () => {
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        log(`Video loaded: ${video.videoWidth}x${video.videoHeight}`, 'success');
                        updateResult('‚úÖ Test video loaded successfully', 'success');
                        document.getElementById('startBtn').disabled = false;
                        document.getElementById('recordBtn').disabled = false;
                        resolve();
                    };
                    video.onerror = () => {
                        reject(new Error('Failed to load video'));
                    };
                });
                
                // Initialize face detection
                await initializeFaceDetection();
                
            } catch (error) {
                log(`Error loading video: ${error.message}`, 'error');
                updateResult(`‚ùå Failed to load test video: ${error.message}`, 'error');
            }
        }

        // Face tracking with smoothing
        function smoothFacePosition(faceId, newBox) {
            const smooth = document.getElementById('smoothTracking').checked;
            if (!smooth) return newBox;
            
            const alpha = 0.3; // Smoothing factor
            const prevBox = faceTracker.get(faceId);
            
            if (!prevBox) {
                faceTracker.set(faceId, newBox);
                return newBox;
            }
            
            const smoothedBox = {
                x: prevBox.x + alpha * (newBox.x - prevBox.x),
                y: prevBox.y + alpha * (newBox.y - prevBox.y),
                width: prevBox.width + alpha * (newBox.width - prevBox.width),
                height: prevBox.height + alpha * (newBox.height - prevBox.height)
            };
            
            faceTracker.set(faceId, smoothedBox);
            return smoothedBox;
        }

        // Process video frame
        async function processFrame() {
            if (!isProcessing || video.paused || video.ended) {
                return;
            }
            
            const startTime = performance.now();
            
            // Draw original video frame
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            try {
                // Detect faces
                const detections = await faceapi.detectAllFaces(
                    video,
                    new faceapi.TinyFaceDetectorOptions({
                        inputSize: 416,
                        scoreThreshold: 0.5
                    })
                );
                
                // Update face count
                document.getElementById('faceCount').textContent = detections.length;
                
                // Draw Laughing Man logo on each face
                detections.forEach((detection, index) => {
                    const box = detection.box;
                    const smoothedBox = smoothFacePosition(index, box);
                    
                    const centerX = smoothedBox.x + smoothedBox.width / 2;
                    const centerY = smoothedBox.y + smoothedBox.height / 2;
                    const radius = Math.max(smoothedBox.width, smoothedBox.height) / 2 * 1.2;
                    
                    logo.draw(ctx, centerX, centerY, radius);
                });
                
                // Update stats
                frameCount++;
                document.getElementById('frameCount').textContent = frameCount;
                
                // Calculate FPS
                const currentTime = performance.now();
                const frameTime = currentTime - lastFrameTime;
                if (frameTime > 0) {
                    const fps = Math.round(1000 / frameTime);
                    document.getElementById('fps').textContent = fps;
                }
                lastFrameTime = currentTime;
                
                // Update processing time
                const processTime = Math.round(currentTime - startTime);
                document.getElementById('processTime').textContent = `${processTime}ms`;
                
                // Log detections periodically
                if (frameCount % 30 === 0) {
                    log(`Frame ${frameCount}: ${detections.length} faces detected`);
                }
                
            } catch (error) {
                log(`Error processing frame: ${error.message}`, 'error');
            }
            
            // Continue to next frame
            requestAnimationFrame(processFrame);
        }

        // Start processing
        async function startProcessing() {
            if (!video || !canvas) {
                updateResult('‚ùå Video not loaded', 'error');
                return;
            }
            
            isProcessing = true;
            frameCount = 0;
            faceTracker.clear();
            
            document.getElementById('startBtn').disabled = true;
            document.getElementById('stopBtn').disabled = false;
            
            log('Starting face detection...', 'success');
            updateResult('üé¨ Face detection started', 'info');
            
            video.play();
            processFrame();
        }

        // Stop processing
        function stopProcessing() {
            isProcessing = false;
            video.pause();
            
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            
            log('Face detection stopped', 'info');
            updateResult(`üõë Processing stopped. Total frames processed: ${frameCount}`, 'info');
        }

        // Start recording
        function startRecording() {
            try {
                if (!canvas || !isProcessing) {
                    updateResult('‚ùå Start face detection first before recording', 'error');
                    return;
                }

                // Force a frame update to ensure canvas has content
                if (canvas.width === 0 || canvas.height === 0) {
                    updateResult('‚ùå Canvas has no content to record', 'error');
                    return;
                }

                // Get canvas stream with explicit frame rate
                const canvasStream = canvas.captureStream(25); // 25 FPS for better compatibility
                
                // Test supported formats
                const supportedTypes = [
                    'video/webm;codecs=vp9',
                    'video/webm;codecs=vp8', 
                    'video/webm',
                    'video/mp4'
                ];
                
                let selectedType = null;
                for (const type of supportedTypes) {
                    if (MediaRecorder.isTypeSupported(type)) {
                        selectedType = type;
                        break;
                    }
                }
                
                if (!selectedType) {
                    throw new Error('No supported video format found');
                }
                
                log(`Using format: ${selectedType}`, 'info');
                
                // Configure MediaRecorder with lower bitrate for compatibility
                const options = {
                    mimeType: selectedType,
                    videoBitsPerSecond: 1000000 // 1 Mbps
                };

                mediaRecorder = new MediaRecorder(canvasStream, options);
                recordedChunks = [];

                mediaRecorder.ondataavailable = function(event) {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                        log(`Recorded chunk: ${event.data.size} bytes`);
                    } else {
                        log('Warning: Received empty data chunk', 'error');
                    }
                };
                
                mediaRecorder.onstart = function() {
                    log('MediaRecorder started successfully', 'success');
                };

                mediaRecorder.onstop = function() {
                    const blob = new Blob(recordedChunks, { type: 'video/webm' });
                    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
                    const filename = `laughing-man-test-${timestamp}.webm`;
                    
                    // Create download link
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.style.display = 'none';
                    a.href = url;
                    a.download = filename;
                    document.body.appendChild(a);
                    a.click();
                    document.body.removeChild(a);
                    URL.revokeObjectURL(url);

                    log(`Video exported: ${filename} (${blob.size} bytes)`, 'success');
                    updateResult(`‚úÖ Video exported: ${filename} (${(blob.size / 1024 / 1024).toFixed(2)} MB)`, 'success');
                    
                    document.getElementById('recordStatus').textContent = 'Ready';
                    document.getElementById('recordBtn').disabled = false;
                    document.getElementById('stopRecordBtn').disabled = true;
                };

                mediaRecorder.onerror = function(event) {
                    log(`Recording error: ${event.error}`, 'error');
                    updateResult(`‚ùå Recording error: ${event.error}`, 'error');
                };

                // Start recording with shorter chunks for better data capture
                mediaRecorder.start(250); // Record in 250ms chunks for better data flow
                isRecording = true;
                
                // Force canvas update to ensure content is being rendered
                if (!isProcessing) {
                    log('Warning: Face detection not running, recording may be empty', 'error');
                }

                document.getElementById('recordBtn').disabled = true;
                document.getElementById('stopRecordBtn').disabled = false;
                document.getElementById('recordStatus').textContent = 'Recording';

                log('Recording started', 'success');
                updateResult('üî¥ Recording started - Laughing Man overlays will be captured', 'success');

            } catch (error) {
                log(`Failed to start recording: ${error.message}`, 'error');
                updateResult(`‚ùå Recording failed: ${error.message}`, 'error');
            }
        }

        // Stop recording
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                document.getElementById('recordStatus').textContent = 'Processing';
                log('Recording stopped, processing video...', 'info');
                updateResult('‚èπÔ∏è Recording stopped, preparing download...', 'info');
            }
        }

        // Auto-initialize on page load
        window.onload = async function() {
            log('Page loaded, auto-initializing...', 'info');
            document.getElementById('initStatus').textContent = 'üîÑ Loading face detection models...';
            
            try {
                // Load models first
                const modelsReady = await initializeFaceDetection();
                if (!modelsReady) {
                    throw new Error('Failed to load face detection models');
                }
                
                document.getElementById('initStatus').textContent = 'üìπ Requesting webcam access...';
                
                // Auto-load webcam
                await loadTestVideo();
                
                document.getElementById('initStatus').innerHTML = '‚úÖ <span style="color: #00FF00;">Ready to test!</span> Click "Start Face Detection" to begin.';
                updateResult('‚úÖ System initialized - Ready for testing', 'success');
                
            } catch (error) {
                log(`Auto-initialization failed: ${error.message}`, 'error');
                document.getElementById('initStatus').innerHTML = '‚ùå <span style="color: #FF0000;">Initialization failed</span> - Check camera permissions';
                updateResult(`‚ùå Auto-initialization failed: ${error.message}`, 'error');
            }
        };
    </script>
</body>
</html>